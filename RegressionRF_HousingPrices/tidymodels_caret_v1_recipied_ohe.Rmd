---
title: "Predicting Housing Prices"
author: "Jeremiah W"
output:
    html_document:
      theme: paper
      highlight: default
      code_folding: hide
      df_print: paged
      toc: true
      toc_depth: 2
      toc_float:
        collapsed: false
        smooth_scroll: false
---
  
```{r}
# global options
#knitr::opts_chunk$set(echo=FALSE)
options(DT.options = list(scrollX = TRUE, paging=TRUE, fixedHeader=TRUE, searchHighlight = TRUE))

```

```{r include = FALSE}
# <style>
# .main-container {
#     width: 100%;
#     max-width: unset;
# }
# </style>
```

```{css echo=FALSE}
# special function defined to call out assumptions/notes
.note {
  color: red;
  font-weight: 700
}
```

```{r results='hide', message=FALSE, warning=FALSE}
#load packages
#default
library(DataExplorer);library(data.table);library(dlookr)
library(extrafont);library(formattable);library(GGally);library(here)
library(janitor);library(lubridate);library(naniar)
library(patchwork);library(PerformanceAnalytics)
library(plotly);library(RColorBrewer);library(readxl)
library(skimr);library(tidyverse);library(scales)
#rmarkdown
library(kableExtra)
#ml
library(caret);library(tidymodels);library(h2o);library(glmnet)
```

# Get & Split the Data

In one piped statement:
  
1. read in data
2. convert char to factor vars
3. rename all colnames lowercase
4. order cols by name: alphabetically
5. order cols by datatype: nominal, then numeric

```{r, message=FALSE}
a = read_csv('train.csv') %>%
  mutate(across(where(is.character),as.factor)) %>%
  clean_names(.) %>% select(sort(tidyselect::peek_vars())) %>%
  select(where(is.factor), where(is.numeric))

split = a %>% initial_split(strata = sale_price)
train = rsample::training(split)
test = rsample::testing(split)
```

# EDA: nom vars

### check head rows
```{r}
train %>% select(where(is.factor)) %>% head %>% DT::datatable()
```

### glimpse structure
```{r}
train %>% select(where(is.factor)) %>% glimpse
```

### check for missing values
```{r}
(miss_var_summary(train %>% select(where(is.factor))) %>% DT::datatable(options = list(scrollY = '500px')))
```

### notes about nom vars with missing data

1. PoolQC: Pool quality
2. MiscFeature: Miscellaneous feature not covered in other categories (e.g. elevator, 2nd garage, tennis court)
3. Alley: Type of alley access to property
4. Fence: Fence quality
5. FireplaceQu: Fireplace quality

### distribution: counts of unique levels
```{r}
sapply(train %>% select(where(is.factor)), n_unique) %>% as.data.frame() %>% arrange(desc(.)) %>% DT::datatable()
```

### reference: names of unique levels
```{r, eval=TRUE}
sapply(train %>% select(where(is.factor)), unique)
```

### distribution: viz
```{r}
DataExplorer::plot_bar(train %>% select(where(is.factor)))
```

# EDA: num vars

### check head rows
```{r}
train %>% select(where(is.numeric)) %>% head %>% DT::datatable()
```

### glimpse structure
```{r}
train %>% select(where(is.numeric)) %>% glimpse
```

### check for missing values
```{r}
(miss_var_summary(train %>% select(where(is.numeric))) %>% DT::datatable(options = list(scrollY = '500px')))

```

### notes about num vars with missing data

1. LotFrontage: Linear feet of street connected to property
2. GarageYrBlt: Year garage was built
3. MasVnrArea: Masonry veneer area in square feet

### distribution: viz
```{r}
DataExplorer::plot_boxplot(train %>% select(where(is.numeric)), by = 'sale_price')
```

### distribution: viz
```{r}
DataExplorer::plot_histogram(train %>% select(where(is.numeric)))
```

### distribution: viz
```{r}
DataExplorer::plot_density(train %>% select(where(is.numeric)))
```

### pairwise correlations: viz
```{r}
GGally::ggcorr(train %>% select(where(is.numeric)), low = '#990000', mid = '#E0E0E0', high = '#009900', label = TRUE)
```

# EDA: other
### check distribution of response var in more detail: right skewed
```{r}
train %>% ggplot(aes(sale_price)) + geom_freqpoly()
train %>% ggplot(aes(sale_price)) + geom_histogram()
summary(train$sale_price)
```

### check for normality in distribution of dependent var
```{r}
qqnorm(train$sale_price)
qqline(train$sale_price, lwd = 2, col = 'darkred')
```

### log10 transformation helps restore normality
```{r}
qqnorm(log10(train$sale_price))
qqline(log10(train$sale_price), lwd = 2, col = 'darkred')
```

# Preprocessing

Reference: (package recipes)[https://recipes.tidymodels.org/reference/index.html]

### create preprocessing recipe
```{r}
(recipe = train %>% recipe(sale_price ~ . ) %>%
    #data conversion
    step_mutate(mo_sold = factor(mo_sold)) %>%
    step_mutate(year_built = factor(year_built)) %>%
    step_mutate(year_remod_add = factor(year_remod_add)) %>%
    step_mutate(yr_sold = factor(yr_sold)) %>%
    step_mutate(garage_yr_blt = factor(garage_yr_blt)) %>% # * has missing data in test set   
   #data imputation: numeric
    step_medianimpute(lot_frontage, mas_vnr_area) %>%
    step_unknown(all_nominal(),-all_outcomes()) %>%   
    #handling potential multicollinearity via filtering
    step_corr(all_numeric(),-all_outcomes()) %>% 
    step_nzv(all_numeric(),-all_outcomes()) %>% 
    step_zv(all_numeric(),-all_outcomes()) %>% 
    #center and scale numeric data
    step_normalize(all_numeric(),-all_outcomes()) %>% 
   ##!!<NOTE> for these 2 vars, test ds has fewer levels than the train ds, so omit!
   step_naomit(year_built, garage_yr_blt)
    #dummy variable creation should occur AFTER normalization of numeric vars
   #step_dummy(all_nominal(),-all_outcomes(), one_hot = TRUE)
     ##!!<NOTE> this is annoying, but if I don't use it I keep getting missing vals in test set
   #step_pca(all_predictors(),-all_outcomes())
)
```
### examine interaction of receipe with train ds
```{r}
(recipe %>% prep())
```

## preprocess train ds & test ds
```{r}
#'Using the recipe, prepare & juice the train ds'
juiced.train = recipe %>% prep(retain=TRUE ) %>% juice %>%
  select(sort(tidyselect::peek_vars())) %>% select(where(is.factor),where(is.numeric))

#'Using the recipe, prepare & bake the test ds'
baked.test = recipe %>% prep(retain=TRUE ) %>% bake(test) %>%
  select(sort(tidyselect::peek_vars())) %>% select(where(is.factor),where(is.numeric))

juiced.train %>% head() %>% DT::datatable()
baked.test %>% head %>% DT::datatable()

```

### sanity check for missing data
```{r}
miss_var_summary(juiced.train)
miss_var_summary(baked.test)
```

### sanity check: nom vars - distribution: viz
```{r}
juiced.train %>% select(where(is.factor)) %>% DataExplorer::plot_bar()
```

### sanity check: num vars - distribution: viz
```{r}
juiced.train %>% select(where(is.numeric)) %>% DataExplorer::plot_histogram()
```

### distribution: viz
```{r}
juiced.train %>% select(where(is.numeric)) %>% DataExplorer::plot_boxplot(by = 'sale_price')
```

### sanity check: num vars - pairwise correlations: viz
```{r cache= TRUE, eval=FALSE}
GGally::ggcorr(juiced.train %>% select(where(is.numeric)), low = '#990000', mid = '#E0E0E0', high = '#009900', label = TRUE)

```

# Simple Modeling

## Random Forest: Modeling and Assessment
```{r}
#!!<NOTE> to analyze var importance, you need an importance arg
# The 'impurity_corrected' importance measure is unbiased in terms of the number of categories and category frequencies and is almost as fast as the standard impurity importance. 
model.rf = ranger::ranger(log10(sale_price) ~ . , data = juiced.train, num.trees = 300, importance = 'impurity_corrected')

model.rf

#viz var importance
model.rf.var.imp = model.rf$variable.importance %>% as.matrix() %>% as.data.frame.matrix() %>% rownames_to_column() %>% rename(var = rowname, imp = V1) %>% arrange(-imp)

model.rf.var.imp %>% ggplot(aes(fct_reorder(var, imp), imp)) + geom_col() + coord_flip()

#make predictions
model.rf.preds = as.vector(predict(model.rf, baked.test, seed = 88)$predictions)

#y, pred
model.rf.df = tibble(y = baked.test$sale_price, preds = 10 ^ model.rf.preds) #undoing log transformation

#viz
model.rf.df %>% ggplot(aes(y, preds)) + geom_point() + geom_smooth(method='lm')

#what is rmse of model? ~31k 
model.rf.df %>% yardstick::rmse(truth = y, estimate = preds)

#compare relative performance
#what does rmse look like rel. to sd of response var?
#what was sd of sales price? ~70 - 80k
sd(test$sale_price)
```

## Elastic Net (LASSO and Ridge)
```{r}
x.train = juiced.train %>% select(-sale_price) %>% data.matrix()
y.train = log10(juiced.train$sale_price)

x.test = baked.test %>% select(-sale_price) %>% data.matrix()
y.test = log10(baked.test$sale_price)

#---------------------------------------------------(0)ridge

model.ridge = cv.glmnet(
  x = x.train, y = y.train,
  type.measure = 'mse',
  alpha = 0, #ridge regression
  family = 'gaussian'
  )

model.ridge$lambda.1se #value of lambda that resulted in simplest model
model.ridge$lambda.min #value of lambda that resulted in the smallest sum of squares

model.ridge.preds = predict(model.ridge, s=model.ridge$lambda.min, new = x.test) ^ 10

#y, pred
model.ridge.df = tibble(y = y.test ^ 10, preds = as.vector(model.ridge.preds)) #undoing log transformation

#viz
model.ridge.df %>% ggplot(aes(y, preds)) + geom_point() + geom_smooth(method='lm')

model.ridge.rmse = sqrt(mean((y.test - model.ridge.preds)^2))

paste0('ridge regression has a rmse of ', formattable::currency(model.ridge.rmse, digits = 0))

#---------------------------------------------------(1)lasso

model.lasso = cv.glmnet(
  x = x.train, y = y.train,
  type.measure = 'mse',
  alpha = 1, #lasso regression
  family = 'gaussian'
  )

model.lasso$lambda.1se #value of lambda that resulted in simplest model
model.lasso$lambda.min #value of lambda that resulted in the smallest sum of squares

model.lasso.preds = predict(model.lasso, s=model.lasso$lambda.min, new = x.test) ^ 10

#y, pred
model.lasso.df = tibble(y = y.test ^ 10, preds = as.vector(model.lasso.preds)) #undoing log transformation

#viz
model.lasso.df %>% ggplot(aes(y, preds)) + geom_point() + geom_smooth(method='lm')

model.lasso.rmse = sqrt(mean((y.test - model.lasso.preds)^2))

paste0('lasso regression has a rmse of ', formattable::currency(model.lasso.rmse, digits = 0))

#---------------------------------------------------(0.5)elastic

model.elastic = cv.glmnet(
  x = x.train, y = y.train,
  type.measure = 'mse',
  alpha = 0.5, #elastic regression
  family = 'gaussian'
  )

model.elastic$lambda.1se #value of lambda that resulted in simplest model
model.elastic$lambda.min #value of lambda that resulted in the smallest sum of squares

model.elastic.preds = predict(model.elastic, s=model.elastic$lambda.min, new = x.test) ^ 10

#y, pred
model.elastic.df = tibble(y = y.test ^ 10, preds = as.vector(model.elastic.preds)) #undoing log transformation

#viz
model.elastic.df %>% ggplot(aes(y, preds)) + geom_point() + geom_smooth(method='lm')

model.elastic.rmse = sqrt(mean((y.test - model.elastic.preds)^2))

paste0('elastic regression has a rmse of ', formattable::currency(model.elastic.rmse, digits = 0))

```


# Simple Modeling Revisted: filtered to Top N VAR IMP

### find top N most important vars
```{r}
N = 50
(model.rf.var.imp.topN = model.rf.var.imp %>% head(N))
```

### Random Forest Modeling and Assessment: High Important Vars Only
```{r}
#filter data to top `r  N ` important vars
juiced.train.filt.imp.vars = juiced.train %>% select(sale_price, model.rf.var.imp.topN$var)

#create rf model
model.rf2 = ranger::ranger(log10(sale_price) ~ . , data = juiced.train.filt.imp.vars, num.trees = 300, importance = 'impurity_corrected')

#check out model
model.rf2

#check out factor importance
model.rf2.var.imp = model.rf2$variable.importance %>% as.matrix() %>% as.data.frame.matrix() %>% rownames_to_column() %>% rename(var = rowname, imp = V1) %>% arrange(-imp)

model.rf2.var.imp %>% ggplot(aes(fct_reorder(var, imp), imp)) + geom_col() + coord_flip()

#create preds
model.rf2.preds = as.vector(predict(model.rf2, baked.test, seed = 88)$predictions)

#y, pred
model.rf2.df = tibble(y = baked.test$sale_price, preds = 10 ^ model.rf2.preds) #undoing log transformation

#viz
model.rf.df %>% ggplot(aes(y, preds)) + geom_point() + geom_smooth(method='lm')

#what is rmse of model? ~32k 
model.rf2.df %>% yardstick::rmse(truth = y, estimate = preds)

```
Commentary

1. When using just the top `r N  ` variables, overall performance doesn't change much
2. Simpler models are faster, and easier to understand, so it's worth filtering down to just these variables in all modeling


# Intermediate Modeling

## Elastic Net (LASSO and Ridge)
```{r}
#elastic net introduction: https://sciphy-stats.com/post/2019-01-25-finalizing-glmnet-models/
#troubleshooting NA RMSE: https://stackoverflow.com/questions/51548255/caret-there-were-missing-values-in-resampled-performance-measures

#10 fold repeatedcv
trControl = caret::trainControl(method = 'cv', number = 10)

#hyperparameter grid
tuneGrid = expand.grid(
  lambda = c(seq(0.01,.2,.005)),
  alpha = 0 #ridge
)

model2.ridge = caret::train(
  x = x.train, y = y.train,
  metric = 'RMSE',
  method = 'glmnet',
  trControl = trControl,
  tuneGrid = tuneGrid
)

#pluck best hyperparameter
bestTune = purrr::pluck(model2.ridge, 'bestTune')

# Plot hyperparameter Lambda against RMSE
plot(model2.ridge)

#finalize model using best hyperparameter

model2.ridge = glmnet::glmnet(
  x = x.train, y = y.train,
  family = 'gaussian',
  alpha = bestTune$alpha, lambda = bestTune$lambda
)

broom::tidy(model2.ridge) %>% select(term, estimate) %>% 
  mutate_at('estimate', round, 2) %>% arrange(-estimate) %>% DT::datatable()


model2.ridge.preds = predict(model2.ridge, x.test) ^ 10

#y, pred
model2.ridge.df = tibble(y = y.test ^ 10, preds = as.vector(model2.ridge.preds)) #undoing log transformation

#viz
model2.ridge.df %>% ggplot(aes(y, preds)) + geom_point() + geom_smooth(method='lm')

model2.ridge.rmse = sqrt(mean((y.test - model2.ridge.preds)^2))

paste0('ridge regression has a rmse of ', formattable::currency(model2.ridge.rmse, digits = 0))

model2.ridge.var.imp = coef(model2.ridge) %>% as.data.frame.matrix() %>% rename(coef = s0) %>% arrange(-coef) 

model2.ridge.var.imp %>% DT::datatable()
```


# AutoML

(h2o AutoML documentation)[https://docs.h2o.ai/h2o-tutorials/latest-stable/h2o-world-2017/automl/index.html]

start h2o
```{r eval=0}
#preprocess entire dataset
h2o.df = recipe %>% prep(retain=TRUE) %>% bake(a)

#select only the vars that were considered important
h2o.df = h2o.df %>% select(sale_price, model.rf.var.imp.topN$var)
#check for missing vars
miss_var_summary(h2o.df)
# Initialise h2o cluster
h2o.init()
# Convert data to h2o frame
h2o.hf <- as.h2o(h2o.df)
# describe dataset
h2o.describe(h2o.hf)
# identify target and features
y <- 'sale_price'
x <- setdiff(colnames(h2o.df), y)
# split data into train & validation sets
sframe <- h2o.splitFrame(h2o.hf, seed = 88)
train <- sframe[[1]]
test <- sframe[[2]]

aml <- h2o.automl(y = y,
                  training_frame = train,
                  leaderboard_frame = test,
                  max_runtime_secs = 30,
                  seed = 88
                  #project_name = "XXX"
                  )

#view leaderboard
print(aml@leaderboard)

#make predictions
aml.preds = predict(aml@leader, test)
```

### automl leader model assessment
```{r eval=0}
print(h2o.performance(aml@leader, test)) #23967.5
```
```{r}

```

