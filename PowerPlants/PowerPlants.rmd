---
title: "Power Plants"
author: 'Jeremiah W'
date: "November 2020"
output:
  rmdformats::readthedown:
    code_folding: hide
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
    fig_width: 6
    fig_height: 4
---

# MISC

```{r eval=FALSE}
# regarding 'readthedown' theme
# https://cran.r-project.org/web/packages/rmdformats/vignettes/introduction.html
```

<style>
    body .main-container {
        max-width: 1000px;
    }
</style>

```{r include=FALSE}
#https://datatables.net/reference/option/
options(DT.options = list(scrollX = TRUE, pagin=TRUE, fixedHeader = TRUE, searchHighlight = TRUE))

library(DataExplorer);library(data.table);library(dlookr);
library(extrafont);library(formattable);library(GGally);library(here);
library(janitor);library(lubridate);library(naniar);
library(patchwork);library(PerformanceAnalytics);
library(plotly);library(RColorBrewer);library(readxl);
library(skimr);library(tidyverse);library(scales)

library(caret);library(tidymodels);library(h2o)

library(rmdformats);
```

# Introduction

[Check out this Kaggle](https://www.kaggle.com/anikannal/solar-power-generation-data)

*This data has been gathered at two solar power plants in India over a 34 day period. It has two pairs of files - each pair has one power generation dataset and one sensor readings dataset. The power generation datasets are gathered at the inverter level - each inverter has multiple lines of solar panels attached to it. The sensor data is gathered at a plant level - single array of sensors optimally placed at the plant.*

## Business Needs

1.  Can we identify the need for panel cleaning/maintenance?
2.  Can we identify faulty or sub-optimally performing equipment?

## Statistical Methods

1. inverter data set
    + anomaly detection, boxplots
2. sensor data set
    + anomaly detection, boxplots
    
# MISC Ideas

1. If we knew the exact location of the powerplants, we could get local weather information
    + find correlation of weather (sunny/cloudy days) to daily yield to discover normal/abnormal inverters & sensors

# Resources / Business Knowledge

1. https://www.certainteed.com/solar/solar-101-abcs-solar-power/
2. https://www.youtube.com/watch?v=ZLgOoMSlS3Y
3. https://us.sunpower.com/solar-array-definition
4. https://tinyurl.com/y6jes78m
5. https://tinyurl.com/yx8mec4c
6. Irradiation
    + https://www.nasa.gov/mission_pages/sdo/science/Solar%20Irradiance.html

# DATA DICTIONARY for Power Generation Inverter data sets

1.  AC\_POWER : Amount of AC power generated by the inverter (source\_key) in this 15 minute interval. Units - kW.
2.  AC\_ : Amount of DC power generated by the inverter (source\_key) in this 15 minute interval. Units - kW.
3.  DAILY\_YIELD : Daily yield is a cumulative sum of power generated on that day, till that point in time.
4.  DATE\_TIME : Date and time for each observation. Observations recorded at 15 minute intervals.
5.  PLANT\_ID : Plant ID - this will be **common for the entire file.**
6.  SOURCE\_KEY : Source key in this file **stands for the inverter id.**
7.  TOTAL\_YIELD : This is the total yield for the inverter till that point in time.

# Power Generation Inverter data set: Plant 1

## Get and Clean Data

```{r message=FALSE}

p1.gd = read_csv('Plant_1_Generation_Data.csv') %>%
  slice_sample(prop = 1) %>% #!!<NOTE>temp, working with a sample of datset for speed purposes
  clean_names() %>%  #lowercase
  select(sort(tidyselect::peek_vars())) %>% #sort cols alphabetically
  select(where(is.factor),where(is.character),where(is.numeric)) #sort cols by data type

#OlsonNames()
#https://stackoverflow.com/questions/41479008/what-is-the-correct-tz-database-time-zone-for-india

p1.gd = p1.gd %>% mutate(
  date_time = as.POSIXct(strptime(p1.gd$date_time, "%d-%m-%Y %H:%M"), tz = 'Asia/Kolkata'),
  source_key = factor(p1.gd$source_key)
) %>% rename(inverter = source_key)

p1.gd$plant_id = NULL

```

### glimpse structure, and sample rows

```{r}
p1.gd %>% slice_sample(n = 10) %>% DT::datatable()
p1.gd %>% glimpse()
```

### check missing values

```{r}
p1.gd %>% miss_var_summary()
```

## EDA: Factor Vars

### counts each factor's unique levels

```{r}
sapply(p1.gd %>% select(where(is.factor)), n_unique) %>% as.data.frame()
```

### reference: names of unique levels

```{r}
sapply(p1.gd %>% select(where(is.factor)), unique) %>% as.data.frame() %>% arrange()
```

### viz: distribution of level counts

```{r}
jpal = colorRampPalette(brewer.pal(8,'Dark2'))(22)

p1.gd %>% count(inverter) %>% plot_ly(y = ~fct_reorder(inverter,n), x = ~n, color = ~inverter, colors = jpal) %>% add_bars(hoverinfo = 'text', text = ~n) %>% hide_legend() %>% layout(
    title = 'Source Key Counts',
    xaxis = list(title = ''),
    yaxis = list(title = '')
    ) 
```

<h style="color: blue; font-size:12px;">Sanity Check - PASS - Pretty much a uniform distribution</h>

## EDA: Numeric Vars

### viz bivariate numeric distribution

```{r}
DataExplorer::plot_boxplot(p1.gd %>% select(where(is.numeric)), by = 'daily_yield')
```


### viz: numeric univariate distributions
```{r}
names.numeric = p1.gd %>% select(where(is.numeric)) %>% names

p1.gd %>% dlookr::plot_normality(
  names.numeric[1],
  names.numeric[2],
  names.numeric[3]
  )
```

<h style="color: blue; font-size:12px;">The 0s for ac/dc power and daily_yield indicate the inverter was powered off for a 'rest day' / maintenanceã€€</h>

### viz: numeric univariate distributions
```{r fig.width= 12}
DataExplorer::plot_density(p1.gd %>% select(where(is.numeric)))
```

<h style="color: blue; font-size:12px;"> Looking at daily yield, we can infer that that on a daily basis most inverters are either having cleaning/maintenance done, or are producing >= 6.5k units of energy.  Looking at total yield, we can infer that for this entire period, most inverters produced around slightly under 6.5 million units of energy, or 7.25 million units of energy </h>

### viz: distributions by 'inverter' factor

```{r}
p1.gd %>% mutate(inverter = fct_reorder(.f = inverter, .x = daily_yield, .fun = median, .desc = TRUE)) %>%
  plot_ly(y = ~inverter, x = ~daily_yield, color = ~inverter, colors = jpal) %>% add_boxplot()%>%
  hide_legend() %>% layout(xaxis = list(title = ''), yaxis = list(title = ''), title = 'Distribution of Daily Yield by Inverter')

p1.gd %>% mutate(inverter = fct_reorder(.f = inverter, .x = ac_power, .fun = median, .desc = TRUE)) %>%
  plot_ly(y = ~inverter, x = ~ac_power, color = ~inverter, colors = jpal) %>% add_boxplot()%>%
  hide_legend() %>% layout(xaxis = list(title = ''), yaxis = list(title = ''), title = 'Distribution of AC Power by Inverter')

p1.gd %>% mutate(inverter = fct_reorder(.f = inverter, .x = dc_power, .fun = median, .desc = TRUE)) %>%
  plot_ly(y = ~inverter, x = ~dc_power, color = ~inverter, colors = jpal) %>% add_boxplot()%>%
  hide_legend() %>% layout(xaxis = list(title = ''), yaxis = list(title = ''), title = 'Distribution of DC Power by Inverter')
```

### viz: cleaning/maintenance days
```{r cache = TRUE, eval=FALSE}
p1.gd %>% arrange(date_time) %>% group_nest(inverter) %>% unnest

p1.gd.plots = p1.gd %>% arrange(date_time) %>% group_nest(inverter) %>% mutate(
  plots = map2(
    .x = data,
    .y = inverter,
    ~ggplot(data = .x, aes(date_time, daily_yield, color = daily_yield == 0, group = 1)) +
      geom_line(size = 1.2) + scale_color_manual(values = c('black','red')) + ggtitle(paste0('Inverter: ', .y))
  ))

p1.gd.plots$plots

```


### correlations: viz

```{r}
p1.gd %>% dlookr::plot_correlate()
```

<h style="color: blue; font-size:12px;">since dc and ac power are just perfectly convertible (like fahrenheit and celsius), they have a perfect correlation</h>

## EDA: Time Series Viz

## Anomoly Plot

```{r warning=FALSE, message=FALSE, fig.width=12, fig.height= 48}
library(anomalize)
# anomalize(data, target, method = c("iqr", "gesd"), alpha = 0.05, max_anoms = 0.2, verbose = FALSE)

# alpha: Controls the width of the "normal" range. Lower values are more conservative while higher values are less prone to incorrectly classifying "normal" observations.
# max_anoms: The maximum percent of anomalies permitted to be identified.

p1.gd.anomalize = p1.gd %>% arrange(date_time) %>% 
  mutate(inverter = fct_reorder(inverter, -daily_yield)) %>% 
  group_by(inverter) %>%
  time_decompose(daily_yield, method = 'twitter', merge = TRUE) %>%
  anomalize(remainder, alpha = 0.05, method = 'gesd') %>%
  time_recompose()

  p1.gd.anomalize %>%
    plot_anomalies(
      ncol = 1,
      alpha_dots = 0.5,
      alpha_circles = 0.5,
      size_circles = 1.5,
      time_recomposed = TRUE,
      alpha_ribbon = 0.05
      ) + scale_y_continuous(labels = comma) +
    labs(x = '', y = 'daily_yield', title = 'daily_yield')
```

<h style="color: red; font-size:12px;">Something abnormal clearly happened between around May 18th to the end of May.  We should investigate the inverters that were affected.</h>

# Power Generation Inverter data set: Plant 2

## Get and Clean Data

```{r message=FALSE}

p2.gd = read_csv('Plant_2_Generation_Data.csv') %>%
  slice_sample(prop = 1) %>% #!!<NOTE>temp, working with a sample of datset for speed purposes
  clean_names() %>%  #lowercase
  select(sort(tidyselect::peek_vars())) %>% #sort cols alphabetically
  select(where(is.POSIXct), where(is.factor),where(is.character),where(is.numeric)) #sort cols by data type

#OlsonNames()
#https://stackoverflow.com/questions/41479008/what-is-the-correct-tz-database-time-zone-for-india

p2.gd = p2.gd %>% mutate(
  source_key = factor(p2.gd$source_key),
) %>% rename(inverter = source_key)

p2.gd$plant_id = NULL

```

### glimpse structure, and sample rows

```{r}
p2.gd %>% slice_sample(n = 10) %>% DT::datatable()
p2.gd %>% glimpse()
```

### check missing values

```{r}
p2.gd %>% miss_var_summary()
```

## EDA: Factor Vars

### counts each factor's unique levels

```{r}
sapply(p2.gd %>% select(where(is.factor)), n_unique) %>% as.data.frame()
```

### reference: names of unique levels

```{r}
sapply(p2.gd %>% select(where(is.factor)), unique) %>% as.data.frame() %>% arrange()
```

### viz: distribution of level counts

```{r}
jpal = colorRampPalette(brewer.pal(8,'Dark2'))(22)

p2.gd %>% count(inverter) %>% plot_ly(y = ~fct_reorder(inverter,n), x = ~n, color = ~inverter, colors = jpal) %>% add_bars(hoverinfo = 'text', text = ~n) %>% hide_legend() %>% layout(
    title = 'Source Key Counts',
    xaxis = list(title = ''),
    yaxis = list(title = '')
    ) 
```

<h style="color: red; font-size:18px;">Sanity Check - FAIL - We should find out why the bottom 4 inverters have fewer counts.  Were they totally out of commission during the abnormal date range aforementioned?</h>

## EDA: Numeric Vars

### viz bivariate numeric distribution

```{r}
DataExplorer::plot_boxplot(p2.gd %>% select(where(is.numeric)), by = 'daily_yield')
```

### viz: numeric univariate distributions

```{r}
names.numeric = p2.gd %>% select(where(is.numeric)) %>% names

p2.gd %>% dlookr::plot_normality(
  names.numeric[1],
  names.numeric[2],
  names.numeric[3],
  names.numeric[4]
  )
```

### viz: numeric univariate distributions

```{r fig.width = 12}
DataExplorer::plot_density(p2.gd %>% select(where(is.numeric)))
```

<h style="color: blue; font-size:12px;"> the inverters clearly have a wide distribution of daily_yield and total yield.  Looking at daily yield, we can infer that that on a daily basis most inverters are either having cleaning/maintenance done, or producing around 3.7k, 7.5k, 9.0k units of energy  Looking at total yield, we can infer that for this entire period, most inverters produced around slightly under 1.3 billion units of energy, or 1.8 billion units of energy.  **This is a lot more than Plant 1.** </h>

### viz: distributions by 'inverter' factor

```{r}
p2.gd %>% mutate(inverter = fct_reorder(.f = inverter, .x = daily_yield, .fun = median, .desc = TRUE)) %>%
  plot_ly(y = ~inverter, x = ~daily_yield, color = ~inverter, colors = jpal) %>% add_boxplot()%>%
  hide_legend() %>% layout(xaxis = list(title = ''), yaxis = list(title = ''), title = 'Distribution of Daily Yield by Inverter')

p2.gd %>% mutate(inverter = fct_reorder(.f = inverter, .x = ac_power, .fun = median, .desc = TRUE)) %>%
  plot_ly(y = ~inverter, x = ~ac_power, color = ~inverter, colors = jpal) %>% add_boxplot()%>%
  hide_legend() %>% layout(xaxis = list(title = ''), yaxis = list(title = ''), title = 'Distribution of AC Power by Inverter')

p2.gd %>% mutate(inverter = fct_reorder(.f = inverter, .x = dc_power, .fun = median, .desc = TRUE)) %>%
  plot_ly(y = ~inverter, x = ~dc_power, color = ~inverter, colors = jpal) %>% add_boxplot()%>%
  hide_legend() %>% layout(xaxis = list(title = ''), yaxis = list(title = ''), title = 'Distribution of DC Power by Inverter')
```

<h style="color: red; font-size:12px;">We should probably investigate why yellowish (Quc1TzYxW2pYoWX), pink (LYwnQax7tkwH5Cb) and purple (Et9kgGMDl729KT4) have so many outliers</h>

### viz: cleaning/maintenance days
```{r cache=TRUE, eval=FALSE}
p2.gd %>% arrange(date_time) %>% group_nest(inverter) %>% unnest

p2.gd.plots = p2.gd %>% arrange(date_time) %>% group_nest(inverter) %>% mutate(
  plots = map2(
    .x = data,
    .y = inverter,
    ~ggplot(data = .x, aes(date_time, daily_yield, color = daily_yield == 0, group = 1)) +
      geom_line(size = 1.2) + scale_color_manual(values = c('black','red')) + ggtitle(paste0('Inverter: ', .y))
  ))

p2.gd.plots$plots

```

### correlations: viz

```{r}
p2.gd %>% dlookr::plot_correlate()
```

<h style="color: blue; font-size:12px;">Since dc and ac power are perfectly convertible (like fahrenheit and celsius), they have a perfect correlation</h>

## EDA: Time Series Viz

## Anomoly Plot

```{r warning=FALSE, message=FALSE, fig.width=12, fig.height=48}
library(anomalize)
# anomalize(data, target, method = c("iqr", "gesd"), alpha = 0.05, max_anoms = 0.2, verbose = FALSE)

# alpha: Controls the width of the "normal" range. Lower values are more conservative while higher values are less prone to incorrectly classifying "normal" observations.
# max_anoms: The maximum percent of anomalies permitted to be identified.

p2.gd.anomalize = p2.gd %>% arrange(date_time) %>% 
  mutate(inverter = fct_reorder(inverter, -daily_yield)) %>% 
  group_by(inverter) %>%
  time_decompose(daily_yield, method = 'twitter', merge = TRUE) %>%
  anomalize(remainder, alpha = 0.05, method = 'gesd') %>%
  time_recompose()

  p2.gd.anomalize %>%
    plot_anomalies(
      ncol = 1,
      alpha_dots = 0.5,
      alpha_circles = 0.5,
      size_circles = 1.5,
      time_recomposed = TRUE,
      alpha_ribbon = 0.05
      ) + scale_y_continuous(labels = comma) +
    labs(x = '', y = 'daily_yield', title = 'daily_yield')
```

<h style="color: red; font-size:18px;">Abnormal activity occurred from May 18th to the end of May.  We hypothesize this was an exogenous factor, as both solar power plants were affected.  In the case of power plant 2, 4 inverters were completely down.</h>

# DATA DICTIONARY for Sensor Reading data sets

1.  IRRADIATION: Amount of irradiation for the 15 minute interval.
2.  DATE\_TIME: Date and time for each observation. Observations recorded at 15 minute intervals.
3.  PLANT\_ID: Plant ID - this will be **common for the entire file.**
4.  SOURCE\_KEY: Stands for the sensor panel id. This will be common for the entire file because **there's only one sensor panel for the plant.**
5.  MODULE\_TEMPERATURE: There's a module (solar panel) attached to the sensor panel. This is the temperature reading for that module.
6.  AMBIENT\_TEMPERATURE: This is the ambient temperature at the plant.

# Sensor Data Set: Plant 1

## Get and Clean Data

```{r message=FALSE}

p1.ws = read_csv('Plant_1_Weather_Sensor_Data.csv') %>%
  slice_sample(prop = 1) %>% #!!<NOTE>temp, working with a sample of datset for speed purposes
  clean_names() %>%  #lowercase
  mutate(across(where(is.character),factor)) %>% 
  select(sort(tidyselect::peek_vars())) %>% #sort cols alphabetically
  select(date_time, where(is.factor), where(is.numeric)) %>% #sort cols by data type
  arrange(date_time)

p1.ws$plant_id = NULL
p1.ws$source_key = NULL

```

### sample rows

```{r}
p1.ws %>% slice_sample(n = 10) %>% DT::datatable()
```

### glimpse structure
```{r}
p1.ws %>% glimpse()
```

### check missing values
```{r}
p1.ws %>% miss_var_summary
```

## EDA: Numeric Vars

### viz: numeric univariate distributions
```{r}
p1.ws %>% select(where(is.numeric)) %>% dlookr::plot_normality()
```

### viz: numeric univariate outlier check
```{r}
p1.ws %>% select(where(is.numeric)) %>% dlookr::diagnose_outlier()
```

```{r}
p1.ws %>% select(where(is.numeric)) %>% DataExplorer::plot_density()
```


### correlations: viz

```{r}
p1.ws %>% dlookr::plot_correlate()
```

```{r}
p1.ws %>% select(where(is.numeric)) %>% GGally::ggcorr(low = '#990000', mid = '#E0E0E0', high = '#009900', label = TRUE)
```
<h style="color: blue; font-size:12px;">irradiation and module_temperature have a perfect correlation, which is to be expected.  </h>

### viz: Time Series w/IQR percentiles
```{r cache=TRUE}
ggplotly(p1.ws %>% ggplot(aes(date_time, ambient_temperature)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = quantile(p1.ws$ambient_temperature, 0.25), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1) +
  geom_hline(yintercept = quantile(p1.ws$ambient_temperature, 0.50), lty = 'dashed', alpha = 0.7, color = 'blue', size = 1.1) +
  geom_hline(yintercept = quantile(p1.ws$ambient_temperature, 0.75), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1)
) %>% layout(title = 'ambient_temperature')

ggplotly(p1.ws %>% ggplot(aes(date_time, irradiation)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = quantile(p1.ws$irradiation, 0.25), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1) +
  geom_hline(yintercept = quantile(p1.ws$irradiation, 0.50), lty = 'dashed', alpha = 0.7, color = 'blue', size = 1.1) +
  geom_hline(yintercept = quantile(p1.ws$irradiation, 0.75), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1)
) %>% layout(title = 'irradiation')

ggplotly(p1.ws %>% ggplot(aes(date_time, module_temperature)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = quantile(p1.ws$module_temperature, 0.25), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1) +
  geom_hline(yintercept = quantile(p1.ws$module_temperature, 0.50), lty = 'dashed', alpha = 0.7, color = 'blue', size = 1.1) +
  geom_hline(yintercept = quantile(p1.ws$module_temperature, 0.75), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1)
) %>% layout(title = 'module_temperature')

```

```{r fig.width = 12}
p1.ws %>% pivot_longer(ambient_temperature:module_temperature) %>% ggplot(aes(date_time, value, color = name)) + geom_line(size = 1.1) + facet_wrap(~name, ncol = 1, scales = 'free_y') + theme(legend.position = 'none')
```

<h style="color: blue; font-size:12px;">Ambient temperature (red) peaks right before May 18th. Interestingly, irradiation and module temperature do not peak on this date. This suggests an exogenous factor was at play, We should investigate.  </h>

## Anomoly Plot

```{r warning=FALSE}
library(anomalize)
# anomalize(data, target, method = c("iqr", "gesd"), alpha = 0.05, max_anoms = 0.2, verbose = FALSE)

# alpha: Controls the width of the "normal" range. Lower values are more conservative while higher values are less prone to incorrectly classifying "normal" observations.
# max_anoms: The maximum percent of anomalies permitted to be identified.

  ggplotly(
  p1.ws %>% arrange(date_time) %>% 
  time_decompose(ambient_temperature, method = 'twitter', merge = TRUE) %>%
  anomalize(remainder, alpha = 0.15, method = 'gesd') %>%
  time_recompose() %>%
    plot_anomalies(
      ncol = 2,
      alpha_dots = 0.5,
      alpha_circles = 0.5,
      size_circles = 2,
      time_recomposed = TRUE,
      alpha_ribbon = 0.05
      ) + scale_y_continuous(labels = comma) +
    labs(x = '', y = 'ambient_temperature', title = 'ambient_temperature')
  )
  
  ggplotly(
  p1.ws %>% arrange(date_time) %>% 
  time_decompose(irradiation, method = 'twitter', merge = TRUE) %>%
  anomalize(remainder, alpha = 0.05, method = 'gesd') %>%
  time_recompose() %>%
    plot_anomalies(
      ncol = 2,
      alpha_dots = 0.5,
      alpha_circles = 0.5,
      size_circles = 2,
      time_recomposed = TRUE,
      alpha_ribbon = 0.05
      ) + scale_y_continuous(labels = comma) +
    labs(x = '', y = 'irradiation', title = 'irradiation')
  )

  ggplotly(
  p1.ws %>% arrange(date_time) %>% 
  time_decompose(module_temperature, method = 'twitter', merge = TRUE) %>%
  anomalize(remainder, alpha = 0.05, method = 'gesd') %>%
  time_recompose() %>%
    plot_anomalies(
      ncol = 2,
      alpha_dots = 0.5,
      alpha_circles = 0.5,
      size_circles = 2,
      time_recomposed = TRUE,
      alpha_ribbon = 0.05
      ) + scale_y_continuous(labels = comma) +
    labs(x = '', y = 'module_temperature', title = 'module_temperature')
  )

```

<h style="color: blue; font-size:12px;">For all features, there are a ton of BOTH lower and upper outliers beginning around May 16th to the end of May, consistent with previous observations.  As a whole, things are  **heating up** in Plant 1.</h>

# Sensor Data Set: Plant 2

## Get and Clean Data

```{r message=FALSE}

p2.ws = read_csv('Plant_2_Weather_Sensor_Data.csv') %>%
  slice_sample(prop = 1) %>% #!!<NOTE>temp, working with a sample of datset for speed purposes
  clean_names() %>%  #lowercase
  mutate(across(where(is.character),factor)) %>% 
  select(sort(tidyselect::peek_vars())) %>% #sort cols alphabetically
  select(date_time, where(is.factor), where(is.numeric)) %>% #sort cols by data type
  arrange(date_time)

p2.ws$plant_id = NULL
p2.ws$source_key = NULL

```

### sample rows

```{r}
p2.ws %>% slice_sample(n = 10) %>% DT::datatable()
```

### glimpse structure
```{r}
p2.ws %>% glimpse()
```

### check missing values
```{r}
p2.ws %>% miss_var_summary
```

## EDA: Numeric Vars

### viz: numeric univariate distributions
```{r}
p2.ws %>% select(where(is.numeric)) %>% dlookr::plot_normality()
```

### viz: numeric univariate outlier check
```{r}
p2.ws %>% select(where(is.numeric)) %>% dlookr::diagnose_outlier()
```

```{r}
p2.ws %>% select(where(is.numeric)) %>% DataExplorer::plot_density()
```


### correlations: viz

```{r}
p2.ws %>% dlookr::plot_correlate()
```

```{r}
p2.ws %>% select(where(is.numeric)) %>% GGally::ggcorr(low = '#990000', mid = '#E0E0E0', high = '#009900', label = TRUE)
```


### viz: Time Series w/IQR percentiles
```{r cache=TRUE}
ggplotly(p2.ws %>% ggplot(aes(date_time, ambient_temperature)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = quantile(p2.ws$ambient_temperature, 0.25), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1) +
  geom_hline(yintercept = quantile(p2.ws$ambient_temperature, 0.50), lty = 'dashed', alpha = 0.7, color = 'blue', size = 1.1) +
  geom_hline(yintercept = quantile(p2.ws$ambient_temperature, 0.75), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1)
) %>% layout(title = 'ambient_temperature')

ggplotly(p2.ws %>% ggplot(aes(date_time, irradiation)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = quantile(p2.ws$irradiation, 0.25), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1) +
  geom_hline(yintercept = quantile(p2.ws$irradiation, 0.50), lty = 'dashed', alpha = 0.7, color = 'blue', size = 1.1) +
  geom_hline(yintercept = quantile(p2.ws$irradiation, 0.75), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1)
) %>% layout(title = 'irradiation')

ggplotly(p2.ws %>% ggplot(aes(date_time, module_temperature)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = quantile(p2.ws$module_temperature, 0.25), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1) +
  geom_hline(yintercept = quantile(p2.ws$module_temperature, 0.50), lty = 'dashed', alpha = 0.7, color = 'blue', size = 1.1) +
  geom_hline(yintercept = quantile(p2.ws$module_temperature, 0.75), lty = 'dashed', alpha = 0.7, color = 'red', size = 1.1)
) %>% layout(title = 'module_temperature')

```

```{r fig.width = 12}
p2.ws %>% pivot_longer(ambient_temperature:module_temperature) %>% ggplot(aes(date_time, value, color = name)) + geom_line(size = 1.1) + facet_wrap(~name, ncol = 1, scales = 'free_y') + theme(legend.position = 'none')
```

<h style="color: blue; font-size:12px;">Unlike Plant 1, for Plant 2, ambient temperature (red) does NOT peak right before May 18th.</h>

## Anomoly Plot

```{r warning=FALSE}
library(anomalize)
# anomalize(data, target, method = c("iqr", "gesd"), alpha = 0.05, max_anoms = 0.2, verbose = FALSE)

# alpha: Controls the width of the "normal" range. Lower values are more conservative while higher values are less prone to incorrectly classifying "normal" observations.
# max_anoms: The maximum percent of anomalies permitted to be identified.
  ggplotly(
  p2.ws %>% arrange(date_time) %>% 
  time_decompose(ambient_temperature, method = 'twitter', merge = TRUE) %>%
  anomalize(remainder, alpha = 0.15, method = 'gesd') %>%
  time_recompose() %>%
    plot_anomalies(
      ncol = 2,
      alpha_dots = 0.5,
      alpha_circles = 0.5,
      size_circles = 2,
      time_recomposed = TRUE,
      alpha_ribbon = 0.05
      ) + scale_y_continuous(labels = comma) +
    labs(x = '', y = 'ambient_temperature', title = 'ambient_temperature')
  )

  ggplotly(
  p2.ws %>% arrange(date_time) %>% 
  time_decompose(irradiation, method = 'twitter', merge = TRUE) %>%
  anomalize(remainder, alpha = 0.05, method = 'gesd') %>%
  time_recompose() %>%
    plot_anomalies(
      ncol = 2,
      alpha_dots = 0.5,
      alpha_circles = 0.5,
      size_circles = 2,
      time_recomposed = TRUE,
      alpha_ribbon = 0.05
      ) + scale_y_continuous(labels = comma) +
    labs(x = '', y = 'irradiation' , title = 'irradiation')
  )
  
  ggplotly(
  p2.ws %>% arrange(date_time) %>% 
  time_decompose(module_temperature, method = 'twitter', merge = TRUE) %>%
  anomalize(remainder, alpha = 0.05, method = 'gesd') %>%
  time_recompose() %>%
    plot_anomalies(
      ncol = 2,
      alpha_dots = 0.5,
      alpha_circles = 0.5,
      size_circles = 2,
      time_recomposed = TRUE,
      alpha_ribbon = 0.05
      ) + scale_y_continuous(labels = comma) +
    labs(x = '', y = 'module_temperature', title = 'module_temperature')
  )

```

<h style="color: blue; font-size:12px;">Ambient Temperature:  Plant 2 sensors were not affected the same way as Plant 1 sensors.  There were mainly ONLY lower outliers, and mostly only on May 19th.  Plant 2 ambient temperature was **colder**, in contradistinction to Plant 1 ambient temperature, which was **hotter**.</h>